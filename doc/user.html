<html><!-- #BeginTemplate "/Templates/docpage.dwt" --><!-- DW6 --><head><!-- #BeginEditable "doctitle" --> <title>GDS User's Guide</title><!-- #EndEditable --> <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"><style type="text/css"><!--code {  font-family: "Courier New", Courier, mono; font-size: 12pt}body {  font-family: Arial, Helvetica, sans-serif; font-size: 12pt}h2 {  font-size: 14pt}td {  font-family: Arial, Helvetica, sans-serif; font-size: 12pt}h1 {  font-size: 16pt}--></style></head><body bgcolor="#FFFFFF" link="#0000FF" vlink="#000099" alink="#009900"><table width="100%" border="1" bordercolor="#FFFFFF" cellpadding="10" cellspacing="10">  <tr bordercolor="#DDDDDD">     <td>      <h1 align="center"><!-- #BeginEditable "title" --><b>GrADS-DODS Server - User's Guide</b><!-- #EndEditable --></h1>    </td>  </tr></table><table width="100%" border="1" bordercolor="#FFFFFF" cellpadding="10" cellspacing="10">  <tr bordercolor="#DDDDDD">     <td><!-- #BeginEditable "body" -->       <h2><b>Table of Contents</b></h2>      <ul>        <li><a href="#1"><b>Accessing data from a web browser</b></a>           <ul>            <li><a href="user.html#1a">Browsing server contents</a> </li>            <li><a href="user.html#1b">Retrieving data subsets as ASCII text</a><b><br>              <br>              </b></li>          </ul>        </li>        <li><b><a href="user.html#2">Accessing data from a DODS-enabled analysis           tool</a> </b>           <ul>            <li><a href="user.html#2a">Opening a dataset and retrieving data subsets</a>            </li>            <li><a href="user.html#2b">Performing remote analysis</a> </li>            <li><a href="user.html#2c">Uploading data</a><b><a href="user.html#2c"><br>              <br>              </a></b></li>          </ul>        </li>        <li><b><a href="user.html#3">Using remote data in scripts</a></b></li>      </ul>      <hr>      <h2><b><a name="1"></a>Accessing data from a web browser </b> </h2>      <p> <b><a name="1a"></a>Browsing server contents </b></p>      <p>To browse a directory of the datasets being served on a GDS, point your         web browser to the base URL of the GDS. This will usually be a URL of         the form <code>http://machine.domain:9090/dods/</code>. </p>      <p>This directory listing will provide links to &quot;info&quot;, &quot;dds&quot;         and &quot;das&quot; for each dataset. The first link provides a Web page         with a brief summary, followed by a complete metadata listing, for the         dataset. The other two provide links to the DODS Data Descriptor Structure,         which specifies the logical structure of the dataset, and Data Attribute         Structure, which provides descriptive information about the dataset.</p>      <p>You can also retrieve a complete dataset listing for a GDS by adding         <code>/xml</code> to its base URL.</p>      <p>If you are given a GDS dataset URL, you can enter that URL in your web         browser, and get the &quot;info&quot; listing. This listing will contain         links back to the dataset directory for the GDS.</p>      <p>Note: Many OPeNDAP data objects with distinct URLs will often be considered         a single &quot;dataset&quot; from a scientific point of view. However,         the word &quot;dataset&quot; is used here in a technical sense, to mean         a single OPeNDAP data object. </p>      <p><a href="#">back to table of contents</a></p>      <p> <b><a name="1b"></a>Retrieving data subsets as ASCII text </b></p>      <p>The GDS can provide subsets of any dataset it is serving, in ASCII comma-delimited         format. To retrieve a subset, enter a URL of the form <code>http://gds-base-url/dataset.ascii?constraint</code>.      </p>      <p>The <code>constraint</code> portion of the URL should be an OPeNDAP constraint         expression. Some basic constraints:</p>      <p>A constraint of the form <code>var</code> will request the complete contents         of the variable. </p>      <p>A constraint of the form <code>var[a:b]</code> will return the subset         of the variable defined by <code>a</code> and <code>b</code>. </p>      <p>A constraint of the form <code>var[a:n:b]</code> will return every <code>n</code>         th element of the subset defined by <code>a</code> and <code>b</code>.      </p>      <p>For subsets of variables with multiple dimensions, each dimension must         have a constraint. So a constraint for a subset of a three-dimensional         variable would appear as <code> var[a1:b1][a2:b2][a3:b3]</code>, or<code>         var[a1:n1:b1][a2:n2:b2][a3:n3:b3]</code></p>      <p><a href="#">back to table of contents</a></p>      <hr>      <h2><b><a name="2"></a>Accessing data with an OPeNDAP-enabled analysis tool</b>      </h2>      <p> <b><a name="2a"></a>Opening a dataset and retrieving data subsets </b></p>      <p>You can retrieve data from a GrADS Data Server using any OPeNDAP-enabled         desktop analysis tool (aka &quot;client&quot;) such as <a href="/grads/" class="plaintextbold">GrADS</a>,         <a href="http://ferret.wrc.noaa.gov/Ferret/" class="plaintextbold">Ferret</a>,         <a href="http://www.mathworks.com/products/matlab/" class="plaintextbold">Matlab</a>,         or <a href="http://www.rsinc.com/idl/" class="plaintextbold">IDL</a>.         To do this, provide a URL instead of a path name to your client's open         command. You can then use the data as if it were a local data set; the         client will automatically retrieve data as needed. You may want to also         read the notes <a href="#3">below</a> on optimizing your scripts to use         remote data. </p>      <p><a href="#">back to table of contents</a></p>      <p><b><a name="2b"></a>Performing remote analysis </b></p>      <p>Remote analysis is very useful for doing calculations on remote data         that use a large quantity of input data but generate a small output, such         as averaging and correlation functions. This type of calculation will         run much faster on the server, and you will only need to download the         small result instead of the entire set of inputs. </p>      <p></p>      <p>In order to do data analysis on the server, you construct a URL containing         a GrADS expression, and then open that URL with your client. The server         will perform the analysis task, and return the results to the client as         a DODS dataset with a single variable called <code>result</code>, containing         the results. This result dataset can then be used exactly as it if were         an original data set (see above). It can even be used as input to further         analysis expressions on the server, allowing calculations that use multiple         stages of intermediate results to be performed remotely.</p>      <p>The URL for an analysis operation is created by appending <span class="code"><code>_expr_</code></span>         to the server's base URL, as follows:<br>        <code> http://machine_name:9090/dods/_expr_<br>        </code>followed immediately         by three sets of curly braces containing arguments, as follows:</p>      <p><code>{dataset1,dataset2,...}{expression}{x1:x2,y1:y2,z1:z2,t1:t2} </code></p>      <p>The first set of curly braces contains a list of all the datasets on         the server that are used in the GrADS expression. If the datasets are         in a subdirectory, the name of the subdirectory should be included in         the dataset name. </p>      <p>Source datasets can include the results of previous analysis expressions,         allowing you to perform multi-stage calculations. To use a previous analysis         result as a source, put its shorthand name in the list of datasets. The         shorthand name for a result dataset is contained in the dataset's <code>title</code>         attribute (in GrADS you can view this by typing <code>q file</code>),         and has the form <code>_expr_nnnn</code> where <code>nnnn</code> will         be some number. </p>      <p>The second set of curly braces contains the GrADS expression to be evaluated.         This describes the actual calculation to be performed, using GrADS syntax         (see the <a href="http://cola.gmu.edu/grads/">GrADS home page</a>). </p>      <p>The third set of curly braces contains the boundaries for the expression         evaluation in world coordinates (latitude, longitude, elevation, time).         These boundaries may not vary in more than three of the four dimensions.         The first three coordinate pairs should be given as real numbers. The         last pair are time coordinates, and should be in the format recognized         by the <code>set time</code> command in GrADS: <code>[hh[mm]z][dd][mon][yyyy]</code>.         For example, <code>0z1jan2000</code>. </p>      <p>Specifically, the analysis is performed as follows:<br>      </p>      <p>1. GrADS is invoked.<br>        2. The source datasets are opened in the order they are listed in the         first set of curly braces <br>        3. The dimension environment is set according to the parameters in the         third set of curly braces. <br>        4. The expression in the second set of curly braces is evaluated and saved         as a new dataset.</p>      <p>Thus, a variable in the <code>n</code>th listed dataset should be referred         to as <code>var_name.n</code> in the analysis expression. For instance,         if <code>dataset2</code> contains a variable called <code>foo</code>,         this variable should be referred to in the expression as <code>foo.2</code>.         The expression will be evaluated against the grid of the first dataset         opened.</p>      <p>Here are some examples of remote analysis, using GrADS as a client. Please         note that for clarity and avoidance of strange browser behavior, the URLs         in the following examples have been split into more than one line because         they are so long, but they should be entered as one line. </p>      <p>       <ol>        <li>Global Averaging:<br>          The following expression will return a timeseries of globally-averaged           monthly mean 500mb geopotential height based on NCEP reanalysis data           being served on the COLA GDS at the Climate Diagnostic Center (<a href="http://monsoondata.org:9090/" class="plaintextbold">http://monsoondata.org:9090/</a>):<br>          <br>          <code>ga-&gt; sdfopen http://monsoondata.org:9090/dods/_expr_{rean3d}<br>          {tloop(aave(z,global))}{0:0,0:0,500:500,jan1948:dec2000} </code><br>          <br>        </li>        <li>Variable Comparison:<br>          A GDS running at NCAR (<a href="http://dataportal.ucar.edu:9191/" class="plaintextbold">http://dataportal.ucar.edu:9191/</a>)           is distributing a set of ensemble members from the &quot;Climate of           the 20th Century&quot; runs of the COLA atmospheric general circulation           model. We will compare the relative humidity &quot;<span class="code">rh</span>&quot;           from the first two datasets, namely "<code>C20C_A</code>" and "<code>C20C_B</code>".           Suppose we want to find a global time-average of their difference at           the 1000 mb level in 1960. Using GrADS as our client, we would open           the following URL: <br>          <br>          <code>ga-&gt; sdfopen http://dataportal.ucar.edu:9191/dods/_expr_{/C20C/C20C_A,/C20C/C20C_B}<br>          {ave((rh.1-rh.2),time=1jan1960,time=1dec1960)}<br>          {0:360,-90:90,1000:1000,1nov1976:1nov1976}<br>          ga-&gt; display result</code><br>          <br>          The analysis results are returned in the variable "result" in the opened           dataset. Note that the world coordinate boundaries specified in the           third set of curly braces fix the time to 1nov1976 -- this can be set           to any arbitrary time because the time dimension specification is overridden           by the GrADS expression which tells the server to average over the period           from January 1960 to December 1960. <br>          <br>        </li>        <li>A More Complex Analysis Operation:<br>          Suppose you wanted to calculate the mean 500mb height anomaly associated           with warm tropical SST anomalies. Use the Reynolds SST Analyses to create           a time series of the area-averaged SST anomaly between 180 and 90W and           10N and 10S. An "ENSO" mask is then defined for SST anomalies greater           than 1 degree. Using this mask, calculate a mean 500mb height from the           the NCEP/NCAR Reanalysis Data associated with the warm SST anomalies.           All these operations are packaged into a single URL: <br>          <br>          <code>ga-&gt; sdfopen http://monsoondata.org:9090/dods/_expr_{ssta,z5a}           <br>          {tmave(const(maskout(aave(ssta.1,lon=-180,lon=-90,lat=-10,lat=10), <br>          aave(ssta.1,lon=-180,lon=-90,lat=-10,lat=10)-1.0),1),<br>          z5a.2(lev=500),t=1, t=600)}<br>          {0:360,0:90,500:500,jan1950:jan1950} </code><br>          <br>          The GrADS script <a href="ftp://grads.iges.org/grads/scripts/sstmask.gs" class="plaintextbold">sstmask.gs</a>           illustrates the use of this example and contains some additional graphics           commands to display the analysis result. </li>      </ol>      <p><a href="#">back to table of contents</a></p>      <p><b> <a name="2c"></a>Uploading data </b></p>      <p>The GDS also allows the client to upload data that can then be used as         a source in analysis expressions. This capability is still in under development. </p>      <p><a href="#">back to table of contents</a></p>      <hr>      <h2><b><a name="3"></a>Using remote data in scripts</b></h2>      <p>You do not <i>have</i> to do anything special to adapt a script to work         with remote data. All you need to do is replace local filenames with URLs.         This is because from your client program's point of view, a remote dataset         behaves exactly like a local dataset except that access is slower. </p>      <p>However, because remote data retrieval is not instantaneous, existing         scripts that do not take this into account may run very slowly. Thus it         is often desirable to modify the script to improve its efficiency. </p>      <p>The key to writing efficient scripts is fine-tuning your use of I/O requests.         DODS-enabled clients such as GrADS only provides the illusion of a continuous         connection with a remote dataset. In fact, a new connection is made to         the server every time you request data from the I/O layer (for instance         by using the "display" command). The speed of these connections is dependent         on network latency and server response time, but is generally much slower         than an equivalent request from a local disk. Thus, reducing the number         of network connections, and the quantity of data sent over the network,         will often significantly speed up your script. </p>      <p>Here are some guidelines for writing efficient scripts. The examples         given use the GrADS scripting language, but the principles apply to most         DODS-enabled clients:</p>      <ul>        <li> <b>Avoid multiple opens. </b>Opening a GDS data file generates as           many as eight separate network requests, so try to avoid opening the           same file more than once. <br>          <br>        </li>        <li><b>Store remote data locally if you plan to reuse it. </b>DODS has           a limited ability to cache remote data locally, the way a web browser           does with web pages. However, this only works when you request the exact           same subset. Thus, if you use different parts of the same remote data           subset in multiple places in your script, you are actually requesting           it multiple times over the network.<br>          <br>          To avoid this, request data once from the server, and then store it           in local memory or on disk. In GrADS, you can do this using 'define'           or 'set gxout fwrite'.<b> </b>For example:<br>          <br>          <code>&nbsp;&nbsp;'sdfopen http://monsoondata.org:9090/dods/model'           <br>          &nbsp;&nbsp;'set lat 22 52'<br>          &nbsp;&nbsp;'set lon 233 295'<br>          &nbsp;&nbsp;'set t 1 5'<br>          &nbsp;&nbsp;'define psfc = ps/100'<br>          &nbsp;&nbsp;'d psfc'<br>          <br>          </code>Now you can use the variable 'psfc' as many times as you wish           in your script without any additional network requests. <br>          <br>          <i>Note to GrADS users:</i> The 'define' command automatically loops           through each time step in the dimension environment, so using 'define'           may not always improve your performance if you are accessing time series           at a single point. For example: <br>          <br>          &nbsp;&nbsp;<code>&nbsp;'set lon -90' <br>          &nbsp;&nbsp;'set lat 40' <br>          &nbsp;&nbsp;'set lev 500'<br>          &nbsp;&nbsp;'set t 1 15' <br>          &nbsp;&nbsp;'define ztser = z' </code><br>          <br>          The above example will result in 15 separate requests for data from           the server, one for each time. Each request will only obtain a single           data value! If time is the only varying dimension, it is far better           to display the data using the 'display' command (which doesn't automatically           loop through time) or, if you're going to display the data more than         once, use 'set gxout fwrite' to preserve a local copy.<br>        <br>          For a more complex example, take a look at the GrADS script <a href="ftp://grads.iges.org/grads/scripts/meteogram.gs" class="plaintextbold">meteogram.gs</a>,           which uses 'define' and the 'set gxout fwrite' commands to draw a graphically           detailed meteogram for any location in the forecast model domain. <br>          <br>        </li>        <li><b>Evaluate expressions on the server side when appropriate.</b> It           may save time and server resources to package your request into an analysis           expression. A good rule of thumb is to use analysis expressions when           the size of the result data set is smaller than the total size of the           input data, e.g. when doing spatial or time averaging.<br>          <br>          For example, the following script example opens two separate MRF forecast           data files and then uses the 'const' function to merge one variable           from each of them to form one continuous time series:<br>          <br>          &nbsp;&nbsp;<code>&nbsp;'sdfopen http://monsoondata.org:9090/dods/gfs.2002010800'<br>          &nbsp;&nbsp;'sdfopen http://monsoondata.org:9090/dods/gfs.2002010800b'<br>          &nbsp;&nbsp;'set lat 0'<br>          &nbsp;&nbsp;'set lon 0'<br>          &nbsp;&nbsp;'set t 1 31'<br>          &nbsp;&nbsp;'define tt = const(t.1,0,-u) + const(t.2,0,-u)'<br>          &nbsp;&nbsp;'d tt' </code><br>          <br>          <span class="plaintext">This second version of the script example creates           the same continuous time series using an analysis expression. This script           runs three times faster than the first version, and hits the server           half as many times. </span> <br>          <br>          <code>&nbsp;&nbsp;baseurl &nbsp;&nbsp;&nbsp;= 'http://monsoondata.org:9090/dods/_expr_'<br>          &nbsp;&nbsp;datasets &nbsp;&nbsp;= '{gfs.2002010800,gfs.2002010800b}'<br>          &nbsp;&nbsp;expression = '{const(t.1,0,-u)+const(t.2,0,-u)}'<br>          &nbsp;&nbsp;dimensions = '{0:0,0:0,1000:1000,00Z08JAN2002:00Z23JAN2002}'<br>          &nbsp;&nbsp;'sdfopen '%baseurl%datasets%expression%dimensions<br>          &nbsp;&nbsp;'set t 1 31'<br>          &nbsp;&nbsp;'define tt = result.1'<br>          &nbsp;&nbsp;'d tt'<br>          </code><br>          Note however, that there is an overhead on the server associated with           each analysis expression. Thus, if the size of the expression output           is the same as, or larger than, its inputs, it will be more efficient           to retrieve the inputs first, and do the analysis locally. <br>          <br>        </li>        <li> <b>Try to move data requests outside loops. </b>If you are looping           over a grid of data points, when possible you should retrieve the whole           area you intend to use with a single request, and store it locally for           use in the loop. Otherwise you will be making a new network request           for each data point inside the loop, which can cause extremely slow           performance. </li>      </ul>      <p><a href="#">back to table of contents</a></p>      <!-- #EndEditable --> </td>  </tr></table></body><!-- #EndTemplate --></html>